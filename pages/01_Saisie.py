import streamlit as st
import pandas as pd
import json
import os
import datetime
import re
from io import StringIO
import csv
import sys
import git
import requests

# Configuration de la page
st.set_page_config(
    page_title="Saisie des M√©tadonn√©es",
    page_icon="üìù",
    layout="wide"
)

# Titre et description
st.title("Saisie des M√©tadonn√©es")
st.markdown("""
Ce formulaire vous permet de cr√©er des fiches de m√©tadonn√©es pour vos tables de donn√©es.
Vous pouvez soit saisir manuellement les informations, soit importer des donn√©es pour d√©tection automatique.
""")

# Fonction pour r√©cup√©rer les dossiers existants dans GitHub
def get_github_producers():
    """R√©cup√®re la liste des producteurs de donn√©es"""
    try:
        # Liste pr√©d√©finie de producteurs pour √©viter les erreurs d'API rate limit
        default_producers = [
            "INSEE", 
            "M√©t√©o France", 
            "Minist√®re de la Transition Ecologique", 
            "Citepa (GES)", 
            "Sit@del (permis de construire)", 
            "Spallian"
        ]
        
        # En local, on peut essayer d'enrichir cette liste avec le contenu du dossier s'il existe
        local_metadata_dir = os.path.join(os.getcwd(), "SGBD", "Metadata")
        if os.path.exists(local_metadata_dir):
            try:
                # Ajouter les dossiers trouv√©s localement
                local_producers = [d for d in os.listdir(local_metadata_dir) 
                                  if os.path.isdir(os.path.join(local_metadata_dir, d))]
                # Fusionner les deux listes sans doublons
                all_producers = list(set(default_producers + local_producers))
                return sorted(all_producers)
            except Exception:
                pass
        
        return sorted(default_producers)
    except Exception as e:
        st.warning(f"Erreur lors de la r√©cup√©ration des producteurs: {str(e)}")
        return ["INSEE", "M√©t√©o France", "Minist√®re de la Transition Ecologique", 
                "Citepa (GES)", "Sit@del (permis de construire)", "Spallian"]

# R√©cup√©rer les producteurs existants
existing_producers = get_github_producers()

# Fonction pour d√©tecter automatiquement le type de donn√©es
def detect_data_type(data_content):
    """D√©tecte automatiquement le type de donn√©es (CSV, JSON, etc.)"""
    data_content = data_content.strip()
    
    # D√©tection JSON
    if (data_content.startswith('{') and data_content.endswith('}')) or \
       (data_content.startswith('[') and data_content.endswith(']')):
        try:
            json.loads(data_content)
            return "json"
        except:
            pass
    
    # D√©tection CSV
    try:
        df = pd.read_csv(StringIO(data_content), sep=None, engine='python')
        if len(df.columns) > 1:
            return "csv"
    except:
        pass
    
    # D√©tection texte tabul√©
    if '\t' in data_content:
        lines = data_content.split('\n')
        if len(lines) > 1 and '\t' in lines[0]:
            return "tsv"
    
    # Par d√©faut, format texte
    return "text"

# Fonction pour d√©tecter automatiquement les colonnes depuis un aper√ßu des donn√©es
def detect_columns_from_data(data_preview):
    try:
        # Essayer de d√©tecter le format (CSV, TSV, etc.)
        if ";" in data_preview:
            delimiter = ";"
        elif "\t" in data_preview:
            delimiter = "\t"
        else:
            delimiter = ","
        
        # Lire les donn√©es
        df = pd.read_csv(StringIO(data_preview), delimiter=delimiter)
        
        # Cr√©er un dictionnaire pour chaque colonne
        columns = []
        for col in df.columns:
            col_type = "varchar"
            # D√©terminer le type de donn√©es
            if pd.api.types.is_numeric_dtype(df[col]):
                if all(df[col].dropna().apply(lambda x: int(x) == x if pd.notnull(x) else True)):
                    col_type = "integer"
                else:
                    col_type = "numeric"
            elif pd.api.types.is_datetime64_dtype(df[col]):
                col_type = "timestamp"
            elif pd.api.types.is_bool_dtype(df[col]):
                col_type = "boolean"
            
            columns.append({
                "name": col,
                "type": col_type,
                "description": ""
            })
        
        return columns
    except Exception as e:
        st.error(f"Erreur lors de la d√©tection des colonnes: {str(e)}")
        return []

# Fonction pour convertir les donn√©es en format standard
def convert_data(data_content, data_type):
    """Convertit les donn√©es au format standard pour le stockage"""
    if data_type == "json":
        return json.loads(data_content)
    
    elif data_type in ["csv", "tsv"]:
        separator = ',' if data_type == "csv" else '\t'
        df = pd.read_csv(StringIO(data_content), sep=separator)
        return df.to_dict(orient="records")
    
    else:  # format texte
        lines = data_content.strip().split('\n')
        return {"content": lines}

# Fonction pour sauvegarder les m√©tadonn√©es
def save_metadata(metadata, producer, table_name):
    """Sauvegarde les m√©tadonn√©es dans les dossiers appropri√©s et synchronise avec Git"""
    # Cr√©er le chemin de dossier si n√©cessaire
    base_dir = os.path.join(os.getcwd(), "SGBD", "Metadata")
    producer_dir = os.path.join(base_dir, producer)
    
    # V√©rifier si nous sommes en mode d√©ploiement (Streamlit Cloud)
    is_deployed = not os.path.exists(os.path.dirname(base_dir))
    
    if is_deployed:
        # En mode d√©ploiement, simuler la sauvegarde
        st.success(f"Mode d√©monstration : les m√©tadonn√©es seraient sauvegard√©es dans {producer}/{table_name}.json")
        st.info("Dans un environnement de production, les m√©tadonn√©es seraient synchronis√©es avec GitHub.")
        
        # Retourner un chemin fictif
        return f"demo_path/{producer}/{table_name}.json"
    
    # Cr√©er les r√©pertoires n√©cessaires
    os.makedirs(producer_dir, exist_ok=True)
    
    # Cr√©er nom de fichier s√©curis√©
    safe_name = re.sub(r'[^\w\-\.]', '_', table_name)
    json_path = os.path.join(producer_dir, f"{safe_name}.json")
    txt_path = os.path.join(producer_dir, f"{safe_name}.txt")
    
    # Sauvegarder en format JSON
    with open(json_path, 'w', encoding='utf-8') as f:
        # Ajouter des m√©tadonn√©es sur le producteur et la table
        metadata["producer"] = producer
        metadata["table_name"] = table_name
        
        # Ajouter la date de cr√©ation/modification
        metadata["last_updated"] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    # Cr√©er aussi un fichier TXT pour une lecture rapide
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(f"Nom de la table: {table_name}\n")
        f.write(f"Producteur: {producer}\n")
        f.write(f"Description: {metadata.get('description', '')}\n")
        f.write(f"Source: {metadata.get('source', '')}\n")
        f.write(f"Ann√©e: {metadata.get('year', '')}\n")
        f.write(f"Contact: {metadata.get('contact', '')}\n")
        f.write(f"Date de cr√©ation: {metadata.get('last_updated', '')}\n\n")
        
        f.write("Colonnes:\n")
        for col in metadata.get('columns', []):
            f.write(f"- {col['name']} ({col['type']}): {col.get('description', '')}\n")
    
    # Synchroniser avec Git si disponible
    try:
        # V√©rifier si nous sommes dans un d√©p√¥t Git
        git_dir = os.path.join(os.getcwd(), ".git")
        if not os.path.exists(git_dir):
            st.success(f"M√©tadonn√©es sauvegard√©es avec succ√®s dans {json_path}")
            st.info("Le dossier n'est pas un d√©p√¥t Git. Les changements ne seront pas synchronis√©s automatiquement.")
            return json_path
        
        # Synchroniser avec Git
        repo = git.Repo(os.getcwd())
        repo.git.add(json_path)
        repo.git.add(txt_path)
        commit_message = f"Ajout/Mise √† jour des m√©tadonn√©es pour {producer}/{table_name}"
        repo.git.commit('-m', commit_message)
        
        # Pousser les modifications vers GitHub
        try:
            repo.git.push("origin", "main")
            st.success(f"M√©tadonn√©es sauvegard√©es et synchronis√©es avec GitHub.")
        except Exception as e:
            st.success(f"M√©tadonn√©es sauvegard√©es localement. La synchronisation vers GitHub a √©chou√©: {str(e)}")
            st.info("N'oubliez pas d'ex√©cuter 'git push' pour synchroniser avec GitHub.")
    except Exception as e:
        st.success(f"M√©tadonn√©es sauvegard√©es avec succ√®s dans {json_path} et {txt_path}")
        st.warning(f"Note: La synchronisation Git n'a pas fonctionn√©. Erreur: {str(e)}")
    
    return json_path

# Initialisation des variables de session
if "columns" not in st.session_state:
    st.session_state["columns"] = []

# Onglets pour les diff√©rentes m√©thodes d'entr√©e
tab1, tab2, tab3 = st.tabs(["Saisie manuelle", "Aper√ßu des donn√©es", "T√©l√©charger un fichier"])

with tab1:
    st.markdown("### Saisie manuelle des m√©tadonn√©es")
    st.info("Remplissez tous les champs pour cr√©er une fiche de m√©tadonn√©es compl√®te.")
    
    # Informations de base pour la saisie manuelle
    manual_name = st.text_input("Nom de la table", help="Nom de la table dans la base de donn√©es")
    
    # S√©lection du producteur de donn√©es
    producer_options = ["Nouveau producteur"] + existing_producers
    producer_selection = st.selectbox("Producteur de donn√©es", producer_options)
    
    if producer_selection == "Nouveau producteur":
        new_producer = st.text_input("Nom du nouveau producteur", 
                              help="Exemple: INSEE, M√©t√©o France, Minist√®re de la Transition Ecologique")
        producer = new_producer
    else:
        producer = producer_selection
    
    # Autres champs de saisie manuelle
    manual_title = st.text_input("Titre", help="Titre descriptif du jeu de donn√©es")
    manual_description = st.text_area("Description", help="Description d√©taill√©e du jeu de donn√©es")
    
    # Informations suppl√©mentaires
    col1, col2 = st.columns(2)
    with col1:
        manual_source = st.text_input("Source", help="Source des donn√©es")
        manual_year = st.text_input("Ann√©e", help="Ann√©e des donn√©es")
    with col2:
        manual_contact = st.text_input("Contact", help="Personne √† contacter pour ces donn√©es")
        manual_frequency = st.selectbox("Fr√©quence de mise √† jour", 
                                     ["Annuelle", "Semestrielle", "Trimestrielle", "Mensuelle", "Hebdomadaire", "Journali√®re", "Temps r√©el", "Ponctuelle", "Non d√©termin√©e"])
    
    # Gestion des champs personnalis√©s
    st.subheader("Champs personnalis√©s")
    
    if "custom_fields" not in st.session_state:
        st.session_state["custom_fields"] = []
    
    if st.button("Ajouter un champ personnalis√©"):
        st.session_state["custom_fields"].append({"key": "", "value": ""})
    
    for i, field in enumerate(st.session_state["custom_fields"]):
        col1, col2, col3 = st.columns([3, 6, 1])
        with col1:
            st.session_state["custom_fields"][i]["key"] = st.text_input(f"Nom du champ {i+1}", value=field["key"], key=f"key_{i}")
        with col2:
            st.session_state["custom_fields"][i]["value"] = st.text_input(f"Valeur du champ {i+1}", value=field["value"], key=f"value_{i}")
        with col3:
            if st.button("X", key=f"delete_field_{i}"):
                st.session_state["custom_fields"].pop(i)
                st.rerun()
    
    # Bouton de sauvegarde pour la saisie manuelle
    if st.button("Sauvegarder les m√©tadonn√©es (saisie manuelle)"):
        if not manual_name:
            st.error("Veuillez sp√©cifier un nom pour ce jeu de donn√©es")
        elif not producer:
            st.error("Veuillez s√©lectionner ou saisir un producteur de donn√©es")
        else:
            try:
                # Cr√©er le dictionnaire de m√©tadonn√©es
                manual_metadata = {
                    "title": manual_title,
                    "description": manual_description,
                    "source": manual_source,
                    "year": manual_year,
                    "contact": manual_contact,
                    "frequency": manual_frequency,
                    "columns": st.session_state["columns"],
                    "custom_fields": {field["key"]: field["value"] for field in st.session_state["custom_fields"] if field["key"]}
                }
                
                # Sauvegarder les m√©tadonn√©es
                file_path = save_metadata(manual_metadata, producer, manual_name)
                st.success(f"M√©tadonn√©es sauvegard√©es avec succ√®s dans {file_path}")
            except Exception as e:
                st.error(f"Erreur lors de la sauvegarde: {str(e)}")

with tab2:
    st.markdown("### D√©tection automatique depuis un aper√ßu")
    st.info("Collez un extrait de vos donn√©es pour d√©tecter automatiquement la structure.")
    
    # Informations de base pour l'aper√ßu
    preview_name = st.text_input("Nom du jeu de donn√©es (aper√ßu)", help="Nom unique pour identifier ce jeu de donn√©es")
    
    # S√©lection du producteur pour l'aper√ßu
    preview_producer_options = ["Nouveau producteur"] + existing_producers
    preview_producer_selection = st.selectbox("Producteur de donn√©es (aper√ßu)", preview_producer_options)
    
    if preview_producer_selection == "Nouveau producteur":
        preview_new_producer = st.text_input("Nom du nouveau producteur (aper√ßu)", 
                                    help="Exemple: INSEE, M√©t√©o France, Minist√®re de la Transition Ecologique")
        preview_producer = preview_new_producer
    else:
        preview_producer = preview_producer_selection
    
    data_content = st.text_area("Collez vos donn√©es ici (CSV, JSON, texte tabul√©, etc.)", height=200)
    
    preview_metadata = {}
    
    if data_content:
        data_type = detect_data_type(data_content)
        st.info(f"Format d√©tect√©: {data_type.upper()}")
        
        try:
            # D√©tecter les colonnes si format tabulaire
            if data_type in ["csv", "tsv"]:
                detected_columns = detect_columns_from_data(data_content)
                if detected_columns:
                    st.success(f"{len(detected_columns)} colonnes d√©tect√©es!")
                    st.subheader("Structure d√©tect√©e:")
                    
                    # Afficher les colonnes en tableau
                    col_data = []
                    for col in detected_columns:
                        col_data.append({"Nom": col["name"], "Type": col["type"], "Description": col["description"]})
                    
                    st.table(pd.DataFrame(col_data))
                    
                    # Ajouter les colonnes aux m√©tadonn√©es
                    preview_metadata["columns"] = detected_columns
            
            # Convertir et afficher un aper√ßu
            metadata_content = convert_data(data_content, data_type)
            st.success("Donn√©es analys√©es avec succ√®s!")
            
            # Aper√ßu des donn√©es
            st.subheader("Aper√ßu")
            if isinstance(metadata_content, list) and len(metadata_content) > 0:
                st.dataframe(pd.DataFrame(metadata_content).head(5))
                preview_metadata["data_sample"] = metadata_content[:5]  # Garder un √©chantillon
            elif isinstance(metadata_content, dict):
                st.json(metadata_content)
                preview_metadata = {**preview_metadata, **metadata_content}
            
            # Bouton de sauvegarde pour l'aper√ßu
            if st.button("Sauvegarder les m√©tadonn√©es (aper√ßu)"):
                if not preview_name:
                    st.error("Veuillez sp√©cifier un nom pour ce jeu de donn√©es")
                elif not preview_producer:
                    st.error("Veuillez s√©lectionner ou saisir un producteur de donn√©es")
                else:
                    try:
                        file_path = save_metadata(preview_metadata, preview_producer, preview_name)
                        st.success(f"M√©tadonn√©es depuis l'aper√ßu sauvegard√©es avec succ√®s dans {file_path}")
                    except Exception as e:
                        st.error(f"Erreur lors de la sauvegarde: {str(e)}")
                
        except Exception as e:
            st.error(f"Erreur lors de l'analyse des donn√©es: {str(e)}")

with tab3:
    st.subheader("T√©l√©chargement de fichier")
    
    # Champs pour les informations de base
    upload_name = st.text_input("Nom du jeu de donn√©es (fichier)", help="Nom unique pour identifier ce jeu de donn√©es")
    
    # S√©lection du producteur pour le t√©l√©chargement
    upload_producer_options = ["Nouveau producteur"] + existing_producers
    upload_producer_selection = st.selectbox("Producteur de donn√©es (fichier)", upload_producer_options)
    
    if upload_producer_selection == "Nouveau producteur":
        upload_new_producer = st.text_input("Nom du nouveau producteur (fichier)", 
                                   help="Exemple: INSEE, M√©t√©o France, Minist√®re de la Transition Ecologique")
        upload_producer = upload_new_producer
    else:
        upload_producer = upload_producer_selection
    
    uploaded_file = st.file_uploader("Choisissez un fichier", type=["csv", "json", "txt", "tsv", "xlsx"])
    
    upload_metadata = {}
    
    if uploaded_file is not None:
        try:
            # D√©terminer le type de fichier
            file_type = uploaded_file.name.split('.')[-1].lower()
            
            if file_type == "json":
                upload_metadata = json.load(uploaded_file)
                st.success("Fichier JSON charg√© avec succ√®s!")
                st.json(upload_metadata)
                
            elif file_type in ["csv", "tsv"]:
                separator = ',' if file_type == "csv" else '\t'
                df = pd.read_csv(uploaded_file, sep=separator)
                
                # D√©tecter les types de colonnes
                columns = []
                for col in df.columns:
                    col_type = "varchar"
                    # D√©terminer le type de donn√©es
                    if pd.api.types.is_numeric_dtype(df[col]):
                        if all(df[col].dropna().apply(lambda x: int(x) == x if pd.notnull(x) else True)):
                            col_type = "integer"
                        else:
                            col_type = "numeric"
                    elif pd.api.types.is_datetime64_dtype(df[col]):
                        col_type = "timestamp"
                    elif pd.api.types.is_bool_dtype(df[col]):
                        col_type = "boolean"
                    
                    columns.append({
                        "name": col,
                        "type": col_type,
                        "description": ""
                    })
                
                upload_metadata["columns"] = columns
                upload_metadata["data_sample"] = df.head(5).to_dict(orient="records")
                
                st.success(f"Fichier {file_type.upper()} charg√© avec succ√®s!")
                
                # Aper√ßu des donn√©es
                st.subheader("Aper√ßu")
                st.dataframe(df.head(5))
                
                # Structure des colonnes
                st.subheader("Structure d√©tect√©e:")
                col_data = []
                for col in columns:
                    col_data.append({"Nom": col["name"], "Type": col["type"], "Description": col["description"]})
                
                st.table(pd.DataFrame(col_data))
                
            elif file_type == "xlsx":
                df = pd.read_excel(uploaded_file)
                
                # D√©tecter les types de colonnes (m√™me logique que pour CSV)
                columns = []
                for col in df.columns:
                    col_type = "varchar"
                    if pd.api.types.is_numeric_dtype(df[col]):
                        if all(df[col].dropna().apply(lambda x: int(x) == x if pd.notnull(x) else True)):
                            col_type = "integer"
                        else:
                            col_type = "numeric"
                    elif pd.api.types.is_datetime64_dtype(df[col]):
                        col_type = "timestamp"
                    elif pd.api.types.is_bool_dtype(df[col]):
                        col_type = "boolean"
                    
                    columns.append({
                        "name": col,
                        "type": col_type,
                        "description": ""
                    })
                
                upload_metadata["columns"] = columns
                upload_metadata["data_sample"] = df.head(5).to_dict(orient="records")
                
                st.success("Fichier Excel charg√© avec succ√®s!")
                
                # Aper√ßu des donn√©es
                st.subheader("Aper√ßu")
                st.dataframe(df.head(5))
                
                # Structure des colonnes
                st.subheader("Structure d√©tect√©e:")
                col_data = []
                for col in columns:
                    col_data.append({"Nom": col["name"], "Type": col["type"], "Description": col["description"]})
                
                st.table(pd.DataFrame(col_data))
                
            elif file_type == "txt":
                content = uploaded_file.read().decode("utf-8")
                data_type = detect_data_type(content)
                upload_metadata = convert_data(content, data_type)
                st.success(f"Fichier texte charg√© et interpr√©t√© comme {data_type.upper()}")
                
                # Aper√ßu
                if isinstance(upload_metadata, list):
                    st.dataframe(pd.DataFrame(upload_metadata).head(5))
                else:
                    st.json(upload_metadata)
            
            # Bouton de sauvegarde pour le t√©l√©chargement
            if st.button("Sauvegarder les m√©tadonn√©es (fichier)"):
                if not upload_name:
                    st.error("Veuillez sp√©cifier un nom pour ce jeu de donn√©es")
                elif not upload_producer:
                    st.error("Veuillez s√©lectionner ou saisir un producteur de donn√©es")
                else:
                    try:
                        file_path = save_metadata(upload_metadata, upload_producer, upload_name)
                        st.success(f"M√©tadonn√©es depuis le fichier sauvegard√©es avec succ√®s dans {file_path}")
                    except Exception as e:
                        st.error(f"Erreur lors de la sauvegarde: {str(e)}")
                
        except Exception as e:
            st.error(f"Erreur lors du chargement du fichier: {str(e)}")

# Section d'informations g√©n√©rales et formulaire
st.markdown("---")
st.markdown("## Colonnes")
st.info("Ajoutez les colonnes de votre table en pr√©cisant leur nom, type et description.")

# Utiliser les colonnes d√©tect√©es si disponibles
if "detected_columns" in st.session_state and st.session_state["detected_columns"]:
    if st.button("Utiliser les colonnes d√©tect√©es"):
        st.session_state["columns"] = st.session_state["detected_columns"]
        st.rerun()

# Bouton pour ajouter une nouvelle colonne
if st.button("Ajouter une colonne"):
    st.session_state["columns"].append({
        "name": "",
        "type": "varchar",
        "description": ""
    })
    st.rerun()

# Affichage des colonnes existantes
for i, col in enumerate(st.session_state["columns"]):
    cols = st.columns([3, 2, 8, 1])
    with cols[0]:
        st.session_state["columns"][i]["name"] = st.text_input(
            f"Nom {i}",
            value=col["name"],
            key=f"col_name_{i}"
        )
    with cols[1]:
        st.session_state["columns"][i]["type"] = st.selectbox(
            f"Type {i}",
            ["varchar", "integer", "numeric", "boolean", "date", "timestamp", "geometry"],
            index=["varchar", "integer", "numeric", "boolean", "date", "timestamp", "geometry"].index(col["type"]) if col["type"] in ["varchar", "integer", "numeric", "boolean", "date", "timestamp", "geometry"] else 0,
            key=f"col_type_{i}"
        )
    with cols[2]:
        st.session_state["columns"][i]["description"] = st.text_input(
            f"Description {i}",
            value=col.get("description", ""),
            key=f"col_desc_{i}"
        )
    with cols[3]:
        if st.button("X", key=f"delete_col_{i}"):
            st.session_state["columns"].pop(i)
            st.rerun()
